{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Enzo Cardoso de Almeida Santos Neto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando bibliotecas\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "import re \n",
    "import matplotlib.pyplot as plt\n",
    "#Caso de erro, instalar no prompt - pip install emoji\n",
    "import emoji\n",
    "from emoji  import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Excel para o treinamento do código\n",
    "base_total = pd.read_excel(\"Valorant.xlsx\", sheet_name=\"Treinamento\")\n",
    "\n",
    "#Série de todos os dados + sua tabela absoluta\n",
    "serie_tudo = pd.Series(base_total.Treinamento)\n",
    "tabela_tudo_absoluta = serie_tudo.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapa 3 - Removendo sinais e separação de emojis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para limpar os sinais básicos e separa emojis.\n",
    "def remocao_de_sinais(texto):\n",
    "    import string\n",
    "    pontuacao = '[!-.:?;]'\n",
    "    padrao = re.compile(pontuacao)\n",
    "    text_subbed = re.sub(padrao, ' ', texto)\n",
    "    letras=[]\n",
    "    for letra in text_subbed:  \n",
    "        letras.append(letra)\n",
    "    i=1\n",
    "    espaço=\" \"\n",
    "    frase_separando_emoji=\"\"\n",
    "    while i<= (len(letras)-1):        \n",
    "        if letras[i] in UNICODE_EMOJI:\n",
    "            frase_separando_emoji+=(espaço)\n",
    "            frase_separando_emoji+=letras[i-1]\n",
    "            frase_separando_emoji+=(espaço)\n",
    "            frase_separando_emoji+=(letras[i])\n",
    "            letras.remove(letras[i])\n",
    "            i+=1\n",
    "        else:\n",
    "            frase_separando_emoji+=(letras[i-1])\n",
    "            i+=1\n",
    "    return frase_separando_emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpando os dados de treinamento \n",
    "tweets_relevantes = open(\"relevante.txt\", \"r\", encoding=\"utf8\")\n",
    "relevante_valorant = remocao_de_sinais((tweets_relevantes.read()).lower())\n",
    "\n",
    "tweets_irrelevantes = open(\"irrelevante.txt\", \"r\", encoding=\"utf8\")\n",
    "irrelevante_valorant = remocao_de_sinais((tweets_irrelevantes.read()).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tabelas relativas e absolutas\n",
    "relevante_relativa = (pd.Series(relevante_valorant.split())).value_counts(True)\n",
    "relevante_absoluta = (pd.Series(relevante_valorant.split())).value_counts()\n",
    "\n",
    "irrelevante_relativa = (pd.Series(irrelevante_valorant.split())).value_counts(True)\n",
    "irrelevante_absoluta = (pd.Series(irrelevante_valorant.split())).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probabilidades\n",
    "probabilidade_relevante = relevante_absoluta.sum()/tabela_tudo_absoluta.sum()\n",
    "probabilidade_irrelevante = irrelevante_absoluta.sum()/tabela_tudo_absoluta.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapa 4 - Performance do classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definindo a função Laplace\n",
    "def laplace(palavra, tabela1, tabela2):\n",
    "    if palavra in tabela1:\n",
    "        x = tabela1[palavra]\n",
    "    else:\n",
    "        x = 0\n",
    "        \n",
    "    if palavra in tabela2:\n",
    "        y = tabela2[palavra]\n",
    "    else:\n",
    "        y = 0 \n",
    "    \n",
    "    prob_relevante = (x + 1)/ (tabela1.sum() + len(set(tabela1+tabela2)))\n",
    "    prob_irrelevante = (y + 1)/ (tabela2.sum() + len(set(tabela1+tabela2)))\n",
    "    return [prob_relevante, prob_irrelevante]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lendo o excel com os tweets de teste.\n",
    "base_teste = pd.read_excel(\"Valorant.xlsx\",sheet_name=\"Teste\")\n",
    "series_tweets = pd.Series(list(base_teste.Teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpando os tweets do teste\n",
    "tweets_prontos = []\n",
    "for tweet in series_tweets:\n",
    "    tweets_prontos.append(remocao_de_sinais(tweet.lower()))\n",
    "\n",
    "\n",
    "#classificador\n",
    "classificacao = {}\n",
    "lista_classificada = []\n",
    "for frase in tweets_prontos:\n",
    "    palavras_da_frase = list(frase.split())\n",
    "    relevante = 1\n",
    "    irrelevante = 1\n",
    "    \n",
    "    for palavra in palavras_da_frase:\n",
    "        \n",
    "        # caso esteja nas duas categorias\n",
    "        if palavra in relevante_absoluta and \\\n",
    "        palavra in irrelevante_absoluta:\n",
    "            relevante *= relevante_relativa[palavra] #20\n",
    "            irrelevante *= irrelevante_relativa[palavra] #21\n",
    "        \n",
    "        #caso esteja somente em relevante\n",
    "        elif palavra in relevante_absoluta and \\\n",
    "        palavra not in irrelevante_absoluta:\n",
    "            relevante *= relevante_relativa[palavra] #26\n",
    "            irrelevante *= laplace(palavra,relevante_absoluta,irrelevante_absoluta)[1]\n",
    "        \n",
    "        #caso esteja somente em irrelevante\n",
    "        elif palavra in irrelevante_absoluta and \\\n",
    "        palavra not in relevante_absoluta:\n",
    "            relevante *= laplace(palavra,relevante_absoluta,irrelevante_absoluta)[0]\n",
    "            irrelevante *= irrelevante_relativa[palavra] #33\n",
    "        \n",
    "        #caso nao esteja em nenhuma categoria\n",
    "        else:\n",
    "            relevante *= laplace(palavra,relevante_absoluta,irrelevante_absoluta)[0]\n",
    "            irrelevante *= laplace(palavra,relevante_absoluta,irrelevante_absoluta)[1]\n",
    "    \n",
    "    #probabilidade da frase(tweet) ser relevante e irrelevante\n",
    "    prob_relevante = probabilidade_relevante*relevante\n",
    "    prob_irrelevante = probabilidade_irrelevante*irrelevante\n",
    "    \n",
    "    #comparacao das probabilidades\n",
    "    if prob_relevante > prob_irrelevante:\n",
    "        classificacao[frase] = 0\n",
    "        lista_classificada.append(0)\n",
    "    else:\n",
    "        classificacao[frase] = 1\n",
    "        lista_classificada.append(1)\n",
    "        \n",
    "classificados = pd.Series(classificacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparando o teste com a classificação \n",
    "for tweet in classificacao:\n",
    "    dic={'Tweet': tweets_prontos, 'Resultado Teste': lista_classificada, 'Classificação': base_teste[\"Classe\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_classificacao = pd.DataFrame(dic, columns=['Tweet','Resultado Teste','Classificação'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de acertos = 56.00000000000001%\n",
      "Porcentagem de erros = 44.0%\n"
     ]
    }
   ],
   "source": [
    "acertos = 0\n",
    "errados = 0\n",
    "\n",
    "#varrendo as respostas\n",
    "for classificado , certo in zip(lista_classificada, base_teste[\"Classe\"]):\n",
    "    if classificado == certo:\n",
    "        acertos += 1\n",
    "    else:\n",
    "        errados += 1\n",
    "        \n",
    "porcentagem_acertos = (acertos / 200) *100\n",
    "porcentagem_errados = (errados / 200) *100\n",
    "\n",
    "\n",
    "print(\"Porcentagem de acertos = {}%\".format(porcentagem_acertos))\n",
    "print(\"Porcentagem de erros = {}%\".format(porcentagem_errados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de verdadeiros positivos: 55.50000000000001%\n",
      "Porcentagem de falsos positivos: 1.5%\n",
      "Porcentagem de verdadeiros negativos: 0.5%\n",
      "Porcentagem de falsos negativos: 42.5%\n"
     ]
    }
   ],
   "source": [
    "verdadeiros_positivo = 0\n",
    "falsos_positivos = 0\n",
    "verdadeiros_negativos = 0\n",
    "falsos_negativos = 0\n",
    "\n",
    "# relevante = 1 e irrelevante = 0\n",
    "\n",
    "for resultado_teste , resultado_certo in zip(lista_classificada, base_teste[\"Classe\"]):\n",
    "    \n",
    "    if resultado_certo == 1 and resultado_teste == 1:\n",
    "        # mensagens relevantes e que são classificadas como relevantes\n",
    "        verdadeiros_positivo += 1\n",
    "        \n",
    "    elif resultado_certo == 0 and resultado_teste == 1:\n",
    "        # mensagens irrelevantes e que são classificadas como relevantes\n",
    "        falsos_positivos += 1\n",
    "        \n",
    "    elif resultado_certo == 0 and resultado_teste == 0:\n",
    "        #mensagens irrelevantes e que são classificadas como irrelevantes\n",
    "        verdadeiros_negativos += 1\n",
    "        \n",
    "    elif resultado_certo == 1 and resultado_teste == 0:\n",
    "        # mensagens relevantes e que são classificadas como irrelevantes\n",
    "        falsos_negativos += 1\n",
    "    \n",
    "Porcentagem_verdadeiros_positivo = (verdadeiros_positivo / 200) *100\n",
    "\n",
    "Porcentagem_falsos_positivos = (falsos_positivos / 200) *100\n",
    "\n",
    "Porcentagem_verdadeiros_negativos = (verdadeiros_negativos / 200) *100\n",
    "\n",
    "Porcentagem_falsos_negativos = (falsos_negativos / 200) *100\n",
    "\n",
    "print(\"Porcentagem de verdadeiros positivos: {}%\".format(Porcentagem_verdadeiros_positivo))\n",
    "print(\"Porcentagem de falsos positivos: {}%\".format(Porcentagem_falsos_positivos))\n",
    "print(\"Porcentagem de verdadeiros negativos: {}%\".format(Porcentagem_verdadeiros_negativos))\n",
    "print(\"Porcentagem de falsos negativos: {}%\".format(Porcentagem_falsos_negativos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapa 5 - Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O classificador foi construído em função de uma suavização de LaPlace, que consiste em separar as palavras de uma frase e calcular sua probabilidade de acordo com quantas vezes aparece, porém como existem palavras que não apareceram na nossa base, para que sua probabilidade não seja zero, adicionamos 1 para o divisor, assim permitindo que uma conta seja feita. Analisando um pouco as frases de dupla negação, o que acontece no modelo, é que como essas palavras são analisadas separadamente, é como se tivesse um acrescimo em palavras negativas, em vez de uma frase positiva. Porém, não faz muita diferença para o modelo atual, já que as categorias estão divididas em \"relevante\" e \"irrelevante\", agora, se fossem divididas em \"Bom\" e \"Ruim\" seria outra história."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas porcentagens importantes para análise:\n",
    "\n",
    "- Verdadeiros positivos: 55.5%\n",
    "- Falsos positivos: 1.5%\n",
    "- Verdadeiros negativos: 0.5%\n",
    "- Falsos negativos: 42.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158 0.5663265306122449\n"
     ]
    }
   ],
   "source": [
    "recall = verdadeiros_positivo / (verdadeiros_positivo + falsos_negativos)\n",
    "precision = verdadeiros_positivo / (verdadeiros_positivo + falsos_positivos)\n",
    "\n",
    "print(precision, recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos definir a precisão de um modelo de Machine Learning como a proporção de predições corretas de uma categoria em relação a todas as previsões feitas dessa categoria. E temos uma precisão de 0,97."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A medida de recall de um modelo de Machine Learning é definido como a proporção de previsões corretas da categoria alvo, Verdadeiros Positivos em relação a soma dos verdadeiros positivos com os Falsos Negativos. E temos uma recall de 0.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7161290322580645"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_score = 2 * ((precision*recall)/(precision+recall))\n",
    "F_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O valor mais alto possível de uma F-score é 1.0, indicando precisão e recuperação perfeitas, e o valor mais baixo possível é 0. Sendo assim temos um F_score de 0.716, indicando que é um modelo de predição bom, mas que aceita melhorias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além da suavização de LaPlace, houve uma correção e separação entre os emojis, para que os mesmos não interferissem nas palavras, mas é sempre possivel melhorar o modelo, algumas formas que tenho pesquisado:\n",
    "- Usando \"n-gramas\", que basicamente consiste em uma sequência contígua de n itens de uma determinada amostra de texto. esta técnica ajudaria em situações com frases e piadas comuns. Links sobre : https://sebastianraschka.com/Articles/2014_naive_bayes_1.html#n-grams, https://blog.xrds.acm.org/2017/10/introduction-n-grams-need/\n",
    "- Fazendo um estudo a fundo em o que os emojis significam em certas combinações de frase/palavras, pois assim daria para separar emojis que façam uma diferença significativa no tweet, ou se é apenas um complemento do que está sendo dito. Link sobre: http://www.scielo.br/scielo.php?script=sci_arttext&pid=S0103-18132016000200379\n",
    "- Assim, para implementar essas duas técnicas acima, seria necessário uma base de tweets maior e com mais categorias, por exemplo, \"muito relevante\", \"relevante\", \"neutro\", \"irrelevante\" e \"muito irrelevante\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após trabalhar novamente com o classificador, uma ideia que vem na mente, usando os tweets, é a calcular a probabilidade a personalidade da pessoa de acordo com os seus tweets, se é uma pessoa mais tímida ou extrvertida, etc. Outra ideia, mas agora usando diferentes tipos de dado, poderia ser calculado a probabilidade de um animal ser macho ou fêmea, de acordo com seu peso, largura, e etc (sendo diferente para cada espécie)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
